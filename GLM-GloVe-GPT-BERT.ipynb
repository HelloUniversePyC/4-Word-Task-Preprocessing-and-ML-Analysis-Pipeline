{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5685a3fb-9bc6-4419-afdf-3c8ff2d35454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wheel\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from mat4py import loadmat\n",
    "import scipy.io\n",
    "import csv\n",
    "import struct\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colormaps\n",
    "#from mne_bids import BIDSPath, read_raw_bids\n",
    "from scipy import stats\n",
    "from scipy.signal import butter, filtfilt,welch\n",
    "from scipy.stats import zscore \n",
    "#from mne.time_frequency import tfr_multitaper\n",
    "import seaborn as sb\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk\n",
    "import tkinter as tk\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import mne\n",
    "#from mne.viz import plot_alignment, snapshot_brain_montage\n",
    "#import mne_bids\n",
    "#from mne.channels import make_standard_montage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f5ad2a-92fb-43a2-95c6-723cab162dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colormaps\n",
    "from mne_bids import BIDSPath, read_raw_bids\n",
    "from scipy.signal import butter, filtfilt\n",
    "from mne.time_frequency import tfr_multitaper\n",
    "import seaborn as sb\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk\n",
    "import tkinter as tk\n",
    "\n",
    "\n",
    "\n",
    "import mne\n",
    "from mne.viz import plot_alignment, snapshot_brain_montage\n",
    "import mne_bids\n",
    "from mne.channels import make_standard_montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c96e1a8-ddc1-44fd-a540-fcc877afaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ecd79c-f7dc-4c37-8eec-561091a936b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c746a0-3425-49bf-8be5-f5f03ede4dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This file contains the tools neccesary to work with GPT-2-XL, GloVe, and BERT embeddings of your choosing and run ridge regressions \n",
    "with subject level and summary graphs. It also runs a GLM model for comparison. This file should only be run after 1)Running pooling file 2) Runnin the data prep file.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd23a88-399f-464c-a070-a5c021016239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following three files are produced after 1)The pooling script 2) The dataprep script<- !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0019f14f-e82d-43a6-bf02-0334fe74a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS = pd.read_csv('./GS_corr.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c6112c-cf0d-406f-94e7-d852c75f3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNS = pd.read_csv('./GNS_corr.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1749a9d-79a4-4e5f-ad95-822ba0ae07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NGNS = pd.read_csv('./NGNS_corr.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9704f6-4f24-4304-bfca-bfaf366c31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNS.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd7464d-d35d-45ad-b60a-86d210775ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_new = GS\n",
    "GNS_new = GNS\n",
    "NGNS_new = NGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd081579-5fdc-4b80-8e5c-f3686434793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42183a7b-8fbc-4e23-a4ae-28e84adceda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import in sentence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe299a4b-a07d-4017-93f7-bda7af20fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data = pd.read_csv('sentence_data.csv.gz', compression = 'gzip')\n",
    "\n",
    "sentence_data.dropna(how = 'any', inplace = True)\n",
    "#Remove rejected subjects \n",
    "sentence_data = sentence_data[(sentence_data['sub_id'] != 3) & (sentence_data['sub_id'] != 17) & (sentence_data['sub_id'] != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d6455-22a7-46e7-baf8-9874807a333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start modeling how to do GLM for each sub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440b5d1-ba07-44ea-8979-54b85662b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start with subject_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6834c86-b2f7-47d6-bbf1-db91f77aabea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data.drop_duplicates(subset = ['w1','w2','w3','w4','modality','sentenceType', 'sub_id'], inplace = True) #Ensure no repeat sentence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb6f6c1-b4fd-43d0-aa18-52feda53e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720d864a-62b4-4122-8291-9088626c03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle numbering the electrodes per subject "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1d94ac-dcc2-45fd-8019-5dbaa808a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = list(set(sentence_data['sub_id']))\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7c1c7-7c22-4e51-9c7e-d3f262b4ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3232af-4f9b-4ed4-a9a9-73976ab3638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_final = pd.concat([GS_new, GNS_new, NGNS_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f843a86-b559-48b6-bb0b-37de0554d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8128a06-bf3f-4744-895d-051e81838e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_final.index = elec_final['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a64f87-cc63-48a9-9bf2-a6089fa5ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_final.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c0363-cfd8-480d-bb91-cdb81256254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a column to nicely aggregate participants and their electrodes\n",
    "elec_final['elec_source'] = \"P\" + elec_final['sub_id'].astype(str) + '_' +elec_final.index.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af14744-9dda-452f-96df-5515a8a6b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_final['elec_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867dc4a8-15a8-41e8-a03b-6bb7ff9e7d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_final.rename(columns = {\"type\": \"sentenceType\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e02d3-403f-4462-9d28-168b93164282",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e5c73-69e6-4461-b801-8c1e033c26bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_final['sentenceType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faa1ecd-c405-4189-805d-6a70dd00e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop flat electrodes\n",
    "start_col = 3\n",
    "end_col = 152\n",
    "\n",
    "# Ensure that end_col does not exceed the number of columns in df\n",
    "end_col = min(end_col, len(elec_final.columns) - 1)\n",
    "\n",
    "# Check and drop rows where all values in the specified columns are zero\n",
    "elec_final = elec_final[(elec_final.iloc[:, start_col:end_col + 1] != 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09123818-f2d0-438a-9269-0fa33b010bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_final.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c85ee7-0f4f-4df9-924f-e5b0c57ad46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data.dropna(how = 'any',inplace= True)\n",
    "sentence_data['sentenceType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af4fde-f4db-4e69-8019-481b447c38a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_final = elec_final.sort_values(by='sub_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d14737-d4c6-4cea-9da1-0fd1221b2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_per = elec_final[elec_final['sentenceType'] == 'GS']['sub_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ab1e0-97e2-4ca5-98ce-47893015a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_per_df = electrodes_per.reset_index()\n",
    "electrodes_per_df.columns = ['participant', 'electrode_count']\n",
    "\n",
    "# Sort by participant number\n",
    "electrodes_per_df = electrodes_per_df.sort_values(by='participant')\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(electrodes_per_df['participant'], electrodes_per_df['electrode_count'], color='skyblue')\n",
    "plt.xlabel('Participant Number')\n",
    "plt.ylabel('Number of Electrodes')\n",
    "plt.title('Count of SEEG Electrodes per Participant')\n",
    "plt.xticks(electrodes_per_df['participant'])\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211ca8c-05f0-4b8f-aaf8-40693006f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c4cc53-c36c-45e7-9c73-af773253a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace4d65-39e3-42cb-bf5e-09f092bf4f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_final.columns[1:152]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f9e3fb-1ed9-477d-90ed-49c9f6a5d096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#GLM code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def prepare_data(df, numeric_columns):\n",
    "    # Convert numpy arrays to float arrays\n",
    "    for col in numeric_columns:\n",
    "        if isinstance(df[col].iloc[0], np.ndarray):\n",
    "            df[col] = df[col].apply(lambda x: x.astype(float))\n",
    "    \n",
    "    # Drop rows with any NaN values\n",
    "    df_clean = df.dropna()\n",
    "    \n",
    "    if len(df_clean) < len(df):\n",
    "        print(f\"Dropped {len(df) - len(df_clean)} rows with NaN values\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Merge the sentence and electrode data on 'sub_id' and 'sentenceType'\n",
    "merged_df = pd.merge(sentence_data, elec_final, on=['sub_id', 'sentenceType'])\n",
    "\n",
    "# Define numeric columns\n",
    "numeric_columns = [str(i) for i in range(151)]  # Assuming columns for gamma power are named '0' to '150'\n",
    "\n",
    "# Prepare the data\n",
    "merged_df = prepare_data(merged_df, numeric_columns)\n",
    "\n",
    "# Create results DataFrame with electrode names as index\n",
    "electrode_names = merged_df['elec_source'].unique()\n",
    "results = pd.DataFrame(index=electrode_names, columns=['GS_MSE', 'GS_R2', 'GS_p_value', 'GNS_MSE', 'GNS_R2', 'GNS_p_value', 'NGNS_MSE', 'NGNS_R2', 'NGNS_p_value'])\n",
    "results.index.name = 'Electrode'\n",
    "\n",
    "# Group the data by electrode\n",
    "electrode_groups = merged_df.groupby('elec_source')\n",
    "\n",
    "for electrode, electrode_df in electrode_groups:\n",
    "    for condition in ['GS', 'GNS', 'NGNS']:\n",
    "        # Filter DataFrame by condition for the current electrode\n",
    "        condition_data = electrode_df[electrode_df['sentenceType'] == condition]\n",
    "        if len(condition_data) == 0:\n",
    "            print(f\"Warning: No data for {condition} in electrode {electrode}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate mean gamma power per sample\n",
    "        y = np.array([arr.mean() for arr in condition_data[numeric_columns].values])\n",
    "        \n",
    "        # Create dummy variables for categorical predictors\n",
    "        X = pd.get_dummies(condition_data[['sentenceType', 'modality']], drop_first=True)\n",
    "        \n",
    "        # Add constant term\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        try:\n",
    "            # Perform GLM using statsmodels\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            y_pred = model.predict(X)\n",
    "            \n",
    "            # Calculate Mean Squared Error and R-squared\n",
    "            mse = mean_squared_error(y, y_pred)\n",
    "            r2 = r2_score(y, y_pred)\n",
    "            \n",
    "            # Store results and p-value\n",
    "            results.loc[electrode, f\"{condition}_MSE\"] = mse\n",
    "            results.loc[electrode, f\"{condition}_R2\"] = r2\n",
    "            results.loc[electrode, f\"{condition}_p_value\"] = model.pvalues[1] if len(model.pvalues) > 1 else np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"Error in electrode {electrode}, condition {condition}: {str(e)}\")\n",
    "            results.loc[electrode, [f\"{condition}_MSE\", f\"{condition}_R2\", f\"{condition}_p_value\"]] = np.nan\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(results.describe())\n",
    "\n",
    "# Print detailed results for a few electrodes\n",
    "print(\"\\nDetailed results for first 5 electrodes:\")\n",
    "print(results.head())\n",
    "\n",
    "# Print data types of columns\n",
    "print(\"\\nData types of columns:\")\n",
    "print(merged_df.dtypes)\n",
    "\n",
    "# Print sample of data\n",
    "print(\"\\nSample of data (first row, first 5 numeric columns):\")\n",
    "for col in numeric_columns[:5]:\n",
    "    print(f\"{col}: {merged_df[col].iloc[0][:5]}\")  # Print first 5 elements of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ad63ba-aaa4-4618-b49f-1c64fa2295a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100bcfc-1d5c-487f-aaef-0d9bf34adf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df[(results_df['R-squared'] > -1) & (results_df['R-squared'] < 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c194bf-00ea-448a-88d3-2c5f4eafc3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affe77a6-6538-4030-9e13-653833c35640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate z-scores for R-squared values\n",
    "results_df['z-score'] = zscore(results_df['R-squared'])\n",
    "\n",
    "# Define outlier criteria (e.g., |z-score| > 3)\n",
    "filtered_results_df = results_df[results_df['z-score'].abs() <= 3]\n",
    "\n",
    "# Drop the z-score column as it's no longer needed\n",
    "filtered_results_df = filtered_results_df.drop(columns=['z-score'])\n",
    "\n",
    "# Save the filtered results to a new CSV\n",
    "filtered_results_df.to_csv('filtered_glm_results_per_electrode.csv', index=False)\n",
    "\n",
    "# Print the number of electrodes before and after filtering\n",
    "print(f\"Number of electrodes before filtering: {len(results_df)}\")\n",
    "print(f\"Number of electrodes after filtering: {len(filtered_results_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b29fcc0-bddf-48ec-8ec7-bdc27187ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results_df[filtered_results_df['R-squared'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39440c3c-1acf-40a7-aacc-3ed8ce49e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['R-squared'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cfbced-396e-4023-b96f-e89726cf401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results_df.to_csv('/Users/klab/Total_Sub_GLM.csv.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7332ca96-c987-4dcf-b5a3-1926d7543418",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['R-squared'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75075624-b21e-4ec6-aea8-2e8222b22124",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df8d49-2a77-4eb2-aa0d-216093177595",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['R-squared'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a7552-3d17-43ca-9664-eaeb851b3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot R-squared values for each electrode\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.bar(results_df['Electrode'], results_df['R-squared'], color='skyblue')\n",
    "plt.title('Subject 14 GLM R^2 per Electrode')\n",
    "plt.xlabel('Electrode')\n",
    "plt.ylabel('R-squared')\n",
    "plt.xticks(rotation=90)  # Rotate electrode labels for better readability\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of tick-labels\n",
    "plt.savefig('r_squared_per_electrode_matplotlib.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38283be6-7bea-4d10-a3f4-14ad3851d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop flat electrodes\n",
    "start_col = 0\n",
    "end_col = 2\n",
    "\n",
    "# Ensure that end_col does not exceed the number of columns in df\n",
    "end_col = min(end_col, len(coefficients_a_v.columns) - 1)\n",
    "\n",
    "# Check and drop rows where all values in the specified columns are zero\n",
    "coefficients_a_v = coefficients_a_v[(coefficients_a_v.iloc[:, start_col:end_col + 1] != 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35bda4-bae0-4e2f-a3cb-6ec6f018dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_elecs = results_df[(results_df['R-squared'] <= 1) & (results_df['R-squared'] >= -1)]\n",
    "\n",
    "coefficients = pd.DataFrame(list(valid_elecs['P-values']))\n",
    "\n",
    "coefficients.dropna(how = 'any', inplace = True)\n",
    "\n",
    "#Drop flat electrodes\n",
    "start_col = 0\n",
    "end_col = 5\n",
    "\n",
    "# Ensure that end_col does not exceed the number of columns in df\n",
    "end_col = min(end_col, len(coefficients.columns) - 1)\n",
    "\n",
    "# Check and drop rows where all values in the specified columns are zero\n",
    "coefficients = coefficients[(coefficients.iloc[:, start_col:end_col + 1] != 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f970357d-95b8-4c5b-b821-14a4f1a0d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_a_v = coefficients[['modality_a','modality_v']]\n",
    "\n",
    "sig_a = coefficients_a_v['modality_a']\n",
    "sig_v = coefficients_a_v['modality_v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5c2616-f98c-4674-8ade-def534221f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690bf66-35a7-4bce-8dec-0f751a2ce81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sig_a[92]\n",
    "del sig_v[92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794078b4-ea49-42b7-822c-645adf24e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_a = dict(sig_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ad49a-c659-4e14-883a-d4402271c712",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_v = dict(sig_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c0256-560f-4c14-adcd-2edaa83fb95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628934bd-5692-408e-bf95-bba56c2ddbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_GS = coefficients[coefficients['sentenceType_GS'] < 0.05]['sentenceType_GS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed289f6f-07a1-4192-97a0-f0df6d71ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_GS = {92: 1.419178e-90}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478d26b-10da-49b5-9b50-9489578af9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_NGNS = {92: 3.701506e-244}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c528d6-668c-4983-a539-dca1f88bd300",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_NGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c16d4e-0abc-4a1c-9d0a-b9c5f9ff7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['P-values'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795a767f-15b7-4e2b-9faf-9e858a44c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_a = coefficients[coefficients['modality_a'] < 0.05]['modality_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad8fff9-7570-4030-a787-f579e38aca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cea4dc-faac-4949-881c-8e93652b8045",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_v = coefficients[coefficients['modality_v'] < 0.05]['modality_v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ad31f-972f-4858-b346-fdeff48d3529",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc84df62-7771-439a-82d1-a064f6af7f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a775c3fa-530d-431f-bf2c-7ad922fac6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_v = dict(sig_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804ccce-a1fe-42f4-ae43-9a261ad07d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213910c0-a08e-438c-8a5b-3db99158818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_NGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee59a1-874d-4752-a9c8-9af413d42d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d893e5be-6c2a-4959-b046-d4366e704d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Convert dictionaries to DataFrames\n",
    "df_a = pd.DataFrame(sig_a.items(), columns=['Electrode', 'p_val_audio'])\n",
    "df_v = pd.DataFrame(sig_v.items(), columns=['Electrode', 'p_val_visual'])\n",
    "\n",
    "# Merge DataFrames on the 'Electrode' column\n",
    "df_merged = pd.merge(df_a, df_v, on='Electrode', how='outer')\n",
    "\n",
    "# Replace NaN values with a higher p-value (e.g., 1) to indicate non-significance\n",
    "df_merged.fillna(1, inplace=True)\n",
    "\n",
    "# Apply -log10 transformation\n",
    "df_merged['neg_log10_p_val_audio'] = -np.log10(df_merged['p_val_audio'])\n",
    "df_merged['neg_log10_p_val_visual'] = -np.log10(df_merged['p_val_visual'])\n",
    "\n",
    "# Function to determine significance level and return corresponding asterisks\n",
    "def significance_asterisks(p_val):\n",
    "    if p_val < 0.001:\n",
    "        return '***'\n",
    "    elif p_val < 0.01:\n",
    "        return '**'\n",
    "    elif p_val < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Add asterisks based on significance\n",
    "df_merged['asterisks_audio'] = df_merged['p_val_audio'].apply(significance_asterisks)\n",
    "df_merged['asterisks_visual'] = df_merged['p_val_visual'].apply(significance_asterisks)\n",
    "\n",
    "# Plotting the grouped bar chart with log-transformed p-values\n",
    "x = np.arange(len(df_merged))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars1 = ax.bar(x - width/2, df_merged['neg_log10_p_val_audio'], width, label='Audio')\n",
    "bars2 = ax.bar(x + width/2, df_merged['neg_log10_p_val_visual'], width, label='Visual')\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Electrode')\n",
    "ax.set_ylabel('-log10(p-value)')\n",
    "ax.set_title('Significant Audiovisual Electrodes Subject 14')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_merged['Electrode'])\n",
    "ax.legend()\n",
    "\n",
    "# Function to add asterisks above the bars\n",
    "def add_asterisks(bars, asterisks):\n",
    "    for bar, asterisk in zip(bars, asterisks):\n",
    "        height = bar.get_height()\n",
    "        if asterisk:\n",
    "            ax.annotate(asterisk,\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 2),  # 2 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom',\n",
    "                        fontsize=10)  # Font size for asterisks\n",
    "\n",
    "add_asterisks(bars1, df_merged['asterisks_audio'])\n",
    "add_asterisks(bars2, df_merged['asterisks_visual'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fccc9ee-8b80-4d69-aecf-9b64284409fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Convert dictionaries to DataFrames\n",
    "df_g = pd.DataFrame(sig_GS.items(), columns=['Electrode', 'p_val_GS'])\n",
    "df_n = pd.DataFrame(sig_NGNS.items(), columns=['Electrode', 'p_val_NGNS'])\n",
    "\n",
    "# Merge DataFrames on the 'Electrode' column\n",
    "df_merged = pd.merge(df_g, df_n, on='Electrode', how='outer')\n",
    "\n",
    "# Replace NaN values with a higher p-value (e.g., 1) to indicate non-significance\n",
    "df_merged.fillna(1, inplace=True)\n",
    "\n",
    "# Apply -log10 transformation\n",
    "df_merged['neg_log10_p_val_GS'] = -np.log10(df_merged['p_val_GS'])\n",
    "df_merged['neg_log10_p_val_NGNS'] = -np.log10(df_merged['p_val_NGNS'])\n",
    "\n",
    "# Function to determine significance level and return corresponding asterisks\n",
    "def significance_asterisks(p_val):\n",
    "    if p_val < 0.001:\n",
    "        return '***'\n",
    "    elif p_val < 0.01:\n",
    "        return '**'\n",
    "    elif p_val < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Add asterisks based on significance\n",
    "df_merged['asterisks_GS'] = df_merged['p_val_GS'].apply(significance_asterisks)\n",
    "df_merged['asterisks_NGNS'] = df_merged['p_val_NGNS'].apply(significance_asterisks)\n",
    "\n",
    "# Plotting the grouped bar chart with log-transformed p-values\n",
    "x = np.arange(len(df_merged))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars1 = ax.bar(x - width/2, df_merged['neg_log10_p_val_GS'], width, label='GS', color = \"purple\" )\n",
    "bars2 = ax.bar(x + width/2, df_merged['neg_log10_p_val_NGNS'], width, label='NGNS', color = \"yellow\")\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Electrode')\n",
    "ax.set_ylabel('-log10(p-value)')\n",
    "ax.set_title('Significant Grammatical Electrode 92 Subject 14')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_merged['Electrode'])\n",
    "ax.legend()\n",
    "\n",
    "# Function to add asterisks above the bars\n",
    "def add_asterisks(bars, asterisks):\n",
    "    for bar, asterisk in zip(bars, asterisks):\n",
    "        height = bar.get_height()\n",
    "        if asterisk:\n",
    "            ax.annotate(asterisk,\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 2),  # 2 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom',\n",
    "                        fontsize=10)  # Font size for asterisks\n",
    "\n",
    "add_asterisks(bars1, df_merged['asterisks_GS'])\n",
    "add_asterisks(bars2, df_merged['asterisks_NGNS'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f150744-26f2-49a1-8232-7cf3cdba5a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_vals = dict(GS_new['sub_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31191a65-34a3-4417-8c16-8f375cb01e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_vals = dict(GS['sub_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800b6dbd-5f50-455e-bed2-ef8350002749",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_count = total_elec['sub_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb255b-a005-45e4-98e9-94a31a2187b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do some language electrode analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8f93f9-c1bb-41fa-98c8-5677d6e356e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do per condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0fa14f-9479-4aac-a5fb-ea55089df417",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prac = GS_new[GS_new['sub_id'] == 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0349bc-6512-4bc7-b959-6cc7262af23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prac.drop(['sub_id', 'type'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a73a3e-e2d7-4d69-b7e7-4f58b1f8bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prac.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410bf666-80e7-4458-9aa4-642806840bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prac.index = plot_prac.index+1 #This needs to be done for all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c2328-4436-4cbd-aefc-cd920718dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from scipy.stats import ttest_ind\n",
    "import mne\n",
    "\n",
    "# Assuming plot_prac is your DataFrame\n",
    "# It should have electrodes as columns and time points as rows\n",
    "\n",
    "# Set up parameters\n",
    "sfreq = 1000  # Sampling frequency in Hz\n",
    "total_duration = 6600  # Total duration of the experiment in milliseconds\n",
    "\n",
    "# Create MNE info object\n",
    "ch_names = plot_prac.columns.tolist()\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq)\n",
    "\n",
    "# Convert DataFrame to numpy array\n",
    "data = plot_prac.values.T  # Transpose to have channels as rows\n",
    "\n",
    "# Create Raw object\n",
    "raw = mne.io.RawArray(data, info)\n",
    "\n",
    "# Define periods\n",
    "periods = {\n",
    "    \"Baseline\": (0, 600),\n",
    "    \"W1\": (600, 1475),\n",
    "    \"W2\": (1475, 2350),\n",
    "    \"W3\": (2350, 3225),\n",
    "    \"W4\": (3225, 4100),\n",
    "    \"Consolidate\": (4100, 5100),\n",
    "    \"Response\": (5100, 6600)\n",
    "}\n",
    "\n",
    "# Find indices corresponding to baseline period\n",
    "baseline_start_idx = int(periods[\"Baseline\"][0] * sfreq / 1000)\n",
    "baseline_end_idx = int(periods[\"Baseline\"][1] * sfreq / 1000)\n",
    "\n",
    "# Calculate baseline mean and standard deviation for each electrode\n",
    "baseline_means = np.mean(data[:, baseline_start_idx:baseline_end_idx], axis=1)\n",
    "baseline_stds = np.std(data[:, baseline_start_idx:baseline_end_idx], axis=1)\n",
    "\n",
    "# Group electrodes into batches (10-15 electrodes per plot)\n",
    "electrode_groups = [ch_names[i:i+15] for i in range(0, len(ch_names), 15)]\n",
    "\n",
    "def plot_in_new_window(group, picks):\n",
    "    root = tk.Tk()\n",
    "    root.title(f'SEEG Data: {\", \".join(group)}')\n",
    "    \n",
    "    fig, axs = plt.subplots(len(picks), 1, figsize=(15, 3*len(picks)), sharex=True)\n",
    "    if len(picks) == 1:\n",
    "        axs = [axs]  # Ensure axs is always a list\n",
    "    \n",
    "    significant_electrodes = set()  # Set to store significant electrodes\n",
    "    \n",
    "    for i, pick in enumerate(picks):\n",
    "        data, times = raw[pick, :]\n",
    "        axs[i].plot(times, data.T, label=group[i], color=plt.cm.rainbow(i/len(picks)))\n",
    "        \n",
    "        # Mark periods\n",
    "        for period, (start, end) in periods.items():\n",
    "            start_prop = start / total_duration\n",
    "            end_prop = end / total_duration\n",
    "            axs[i].axvline(x=start_prop * times[-1], color='black', linestyle='--', linewidth=0.5)\n",
    "            axs[i].axvline(x=end_prop * times[-1], color='black', linestyle='--', linewidth=0.5)\n",
    "            axs[i].annotate(period, xy=((start_prop + end_prop) / 2 * times[-1], axs[i].get_ylim()[1]), \n",
    "                            xycoords='data', ha='center', va='bottom', \n",
    "                            bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", ec=\"black\", lw=1))\n",
    "        \n",
    "        # Find and mark the maximum value in each word period if significant\n",
    "        for period in [\"W1\", \"W2\", \"W3\", \"W4\"]:\n",
    "            start, end = periods[period]\n",
    "            start_prop = start / total_duration\n",
    "            end_prop = end / total_duration\n",
    "            start_idx = int(start_prop * len(times))\n",
    "            end_idx = int(end_prop * len(times))\n",
    "            period_data = data[:, start_idx:end_idx]\n",
    "            if period_data.size > 0:  # Ensure the array is not empty\n",
    "                max_val = np.max(period_data)\n",
    "                max_time = times[start_idx:end_idx][np.argmax(period_data)]\n",
    "                \n",
    "                # Perform t-test between baseline and period data\n",
    "                t_stat, p_val = ttest_ind(data[:, baseline_start_idx:baseline_end_idx].flatten(), period_data.flatten())\n",
    "                \n",
    "                # Annotate if p-value is significant (e.g., p < 0.05)\n",
    "                if p_val < 0.05:\n",
    "                    axs[i].plot(max_time, max_val, 'ro')\n",
    "                    \n",
    "                    # Compare maximum value with baseline statistics\n",
    "                    if max_val > baseline_means[pick] + 3 * baseline_stds[pick]:\n",
    "                        axs[i].annotate(f'Significant\\nMax: {max_val:.2f}', (max_time, max_val), \n",
    "                                        xytext=(5, 5), textcoords='offset points',\n",
    "                                        bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", ec=\"black\", lw=1))\n",
    "                        significant_electrodes.add(group[i])  # Add to significant electrodes\n",
    "        \n",
    "        axs[i].set_ylabel(group[i])\n",
    "        axs[i].legend()\n",
    "    \n",
    "    axs[-1].set_xlabel('Time (s)')\n",
    "    axs[-1].set_xlim(0, times[-1])  # Set x-axis limit to the full duration of the data\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    canvas = FigureCanvasTkAgg(fig, master=root)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack()\n",
    "    \n",
    "    # Create a text widget to display significant electrodes\n",
    "    text_widget = tk.Text(root, height=5, width=50)\n",
    "    text_widget.pack()\n",
    "    text_widget.insert(tk.END, \"Significant Electrodes:\\n\")\n",
    "    text_widget.insert(tk.END, \", \".join(sorted(significant_electrodes)))\n",
    "    \n",
    "    root.mainloop()\n",
    "    \n",
    "    return significant_electrodes  # Return the set of significant electrodes\n",
    "\n",
    "# Plot each group of electrodes and collect significant electrodes\n",
    "all_significant_electrodes = set()\n",
    "for group in electrode_groups:\n",
    "    picks = [info.ch_names.index(ch_name) for ch_name in group]\n",
    "    significant_electrodes = plot_in_new_window(group, picks)\n",
    "    all_significant_electrodes.update(significant_electrodes)\n",
    "\n",
    "# After all windows are closed, print the complete list of significant electrodes\n",
    "print(\"All Significant Electrodes:\")\n",
    "print(\", \".join(sorted(all_significant_electrodes)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea6c96-05c4-422f-8495-baf86ff6f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_language = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f18d2-1b74-4d71-9384-c811f95c7753",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_language[14] = all_significant_electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1ef6f-f88a-4395-8d21-4662af03f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8cb38e-faf7-48dc-8771-7aef7bc54b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_count = sentence_data['modality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b704b-c88f-42c9-946e-e32d888a51b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe5c48-cde7-4777-8938-1651c6c51321",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))  # Set the figure size (optional)\n",
    "mod_count.plot(kind='bar')\n",
    "\n",
    "# Customize the plot (optional)\n",
    "plt.title('Histogram of Value Counts')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb97b71-876a-4778-9413-e7a9279e6f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size (optional)\n",
    "sen_dis.plot(kind='bar')\n",
    "\n",
    "# Customize the plot (optional)\n",
    "plt.title('Histogram of Value Counts')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7ca8f-0e66-4ddc-9102-7bfde5e48c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size (optional)\n",
    "elec_count.plot(kind='bar')\n",
    "\n",
    "# Customize the plot (optional)\n",
    "plt.title('Histogram of Value Counts')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553f2aab-70cc-43c5-b86d-bc334b2b7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_elec[total_elec['sub_id'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101fb6e8-d86a-4f43-bdd2-30123c42dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ba3ad-0ffc-4716-ba2f-fa5be389c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_elec.rename(columns = {\"type\":\"sentenceType\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cace95-a4d2-4e37-98a4-6cd2c8577dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9093f2d6-c766-44a6-817b-301c7af2ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional preprocessing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d14c66-56b4-4c1c-9139-8b4381de67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping flat electrodes\n",
    "start_col = 0\n",
    "end_col = 150\n",
    "\n",
    "# Ensure that end_col does not exceed the number of columns in df\n",
    "end_col = min(end_col, len(total_elec.columns) - 1)\n",
    "\n",
    "# Check and drop rows where all values in the specified columns are zero\n",
    "total_elec = total_elec[(total_elec.iloc[:, start_col:end_col + 1] != 0).any(axis=1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576eac2f-ff14-4e2d-86a3-55ca5b2f3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260e3b7-4f4e-4fc5-9cd3-c98ab261d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLoVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c034ff-6710-4116-92a8-24a8e2c63936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbe869-5ac8-4bdc-8fff-662f74c3b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting embeddings from GloVe\n",
    "def load_glove_model(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        glove_model = {}\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "            glove_model[word] = embedding\n",
    "    return glove_model\n",
    "\n",
    "glove_file = '/Users/klab/Desktop/glove.42B.300d.txt'  # Path to your extracted GloVe file\n",
    "glove_model = load_glove_model(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b4b91-10e7-4a40-86b7-34eb8bb82911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of \"noise\" columns not relevant to analysis\n",
    "sentence_solo_total = sentence_data[['w1','w2','w3','w4','modality','sentenceType', 'sub_id']]\n",
    "sentence_solo_total.drop_duplicates(subset =['w1','w2','w3','w4','modality','sentenceType'], inplace = True)\n",
    "sentence_solo_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb80345-8e5c-4db2-8ca1-0c4df7a7bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to populate flat lists with each sentence, one index per sentence\n",
    "sentences = []\n",
    "#contains the modalilities and sentence types for look-up\n",
    "lookup_list = []\n",
    "for i, row in sentence_solo_total.iterrows():\n",
    "    curr_sen = []\n",
    "    curr_lookup = []\n",
    "    #Add each individual word\n",
    "    curr_sen.append(row['w1'])\n",
    "    curr_sen.append(row['w2'])\n",
    "    curr_sen.append(row['w3'])\n",
    "    curr_sen.append(row['w4'])\n",
    "    #Append to list \n",
    "    sentences.append(curr_sen)\n",
    "    #add lookup values\n",
    "    curr_lookup.append(row['modality'])\n",
    "    curr_lookup.append(row['sentenceType'])\n",
    "    curr_lookup.append(row['sub_id'])\n",
    "    lookup_list.append(curr_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f1ee36-5f3f-4eef-86f5-c6ba2b77fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lookup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecf7e6-fefc-4dea-bb06-fdf7fe8bbb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00f7c6-0384-4d9b-a9c1-a0a0c1034fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence, model):\n",
    "    embeddings = [model[word] for word in sentence if word in model]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(300)\n",
    "\n",
    "# Extract embeddings for each sentence\n",
    "sentence_embeddings = np.array([get_sentence_embedding(sentence, glove_model) for sentence in sentences_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd1852-872f-4d9d-95e8-0c56f8f89192",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81da70d-d7a5-4d2c-b14f-e56c163c2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1500 ms between each timestamp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734b0e85-87ae-40fd-a13c-a163c9f31343",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81999a34-c934-43bb-9578-783d66880b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_df = pd.DataFrame(lookup_list, columns=['modality', 'sentenceType','sub_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcaf5a5-67c5-4cbd-b365-8010f6d9d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_df.to_csv('lookupdf.csv.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7d9f51-0e07-42fd-998f-e750976133a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb0fc2-300f-450d-9750-770ee6973388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the standard ridge regression code to run to compare to GloVe embeddings, BERT embeddings, or GPT embeddings. To choose which \n",
    "to compare edit this line filtered_embeddings = gpt_embeddings[sentence_indices] to reflect the name of your desired embeddings.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create results DataFrame with the desired columns\n",
    "results = pd.DataFrame(columns=['Electrode', 'GS_MSE', 'GS_R2', 'GNS_MSE', 'GNS_R2', 'NGNS_MSE', 'NGNS_R2'])\n",
    "\n",
    "# Group the data by electrode\n",
    "electrode_groups = elec_final.groupby('elec_source')\n",
    "\n",
    "# Initialize a scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for electrode, electrode_df in electrode_groups:\n",
    "    result_row = {'Electrode': electrode}\n",
    "    for condition in ['GS', 'GNS', 'NGNS']:\n",
    "        # Filter DataFrame by condition for the current electrode\n",
    "        condition_data = electrode_df[electrode_df['sentenceType'] == condition]\n",
    "        if len(condition_data) == 0:\n",
    "            print(f\"Warning: No data for {condition} in electrode {electrode}\")\n",
    "            result_row[f'{condition}_MSE'] = np.nan\n",
    "            result_row[f'{condition}_R2'] = np.nan\n",
    "            continue\n",
    "        \n",
    "        # Filter sentence embeddings based on condition\n",
    "        condition_lookup = lookup_df[lookup_df['sentenceType'] == condition]\n",
    "        sentence_indices = condition_lookup.index\n",
    "        filtered_embeddings = gpt_embeddings[sentence_indices] #Swap out the name of the list here to change to BERT or GloVe\n",
    "        \n",
    "        # Extract neural data for the current electrode and condition\n",
    "        y = condition_data.iloc[:, 2:153].values.flatten()  # Use all 151 timestamps\n",
    "        \n",
    "        # Ensure y and filtered_embeddings have the same length\n",
    "        if len(filtered_embeddings) > len(y):\n",
    "            filtered_embeddings = filtered_embeddings[:len(y)]\n",
    "        elif len(y) > len(filtered_embeddings):\n",
    "            y = y[:len(filtered_embeddings)]\n",
    "        \n",
    "        # Standardize the embeddings\n",
    "        X = scaler.fit_transform(filtered_embeddings)\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Perform Ridge Regression using sklearn\n",
    "        ridge = Ridge(alpha=2.0)  # Adjust the alpha parameter if necessary\n",
    "        ridge.fit(X_train, y_train)\n",
    "        y_pred_train = ridge.predict(X_train)\n",
    "        y_pred_test = ridge.predict(X_test)\n",
    "        \n",
    "        # Calculate Mean Squared Error and R-squared for both training and testing sets\n",
    "        mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "        r2_train = r2_score(y_train, y_pred_train)\n",
    "        mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "        \n",
    "        # Diagnostics: print mean and variance of y and y_pred\n",
    "        print(f\"Electrode: {electrode}, Condition: {condition}\")\n",
    "        print(f\"y_train mean: {np.mean(y_train)}, y_train variance: {np.var(y_train)}\")\n",
    "        print(f\"y_pred_train mean: {np.mean(y_pred_train)}, y_pred_train variance: {np.var(y_pred_train)}\")\n",
    "        print(f\"Train MSE: {mse_train}, Train R2: {r2_train}\")\n",
    "        print(f\"y_test mean: {np.mean(y_test)}, y_test variance: {np.var(y_test)}\")\n",
    "        print(f\"y_pred_test mean: {np.mean(y_pred_test)}, y_pred_test variance: {np.var(y_pred_test)}\")\n",
    "        print(f\"Test MSE: {mse_test}, Test R2: {r2_test}\")\n",
    "        \n",
    "        # Store results\n",
    "        result_row[f'{condition}_MSE'] = mse_test\n",
    "        result_row[f'{condition}_R2'] = r2_test\n",
    "    \n",
    "    results = pd.concat([results, pd.DataFrame([result_row])], ignore_index=True)\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c4c54-b2ef-4148-b0fc-58e4fc693630",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_results = gs_results[(gs_results['R2'] < 1) & (gs_results['R2'] > -1)]\n",
    "gns_results = gns_results[(gns_results['R2'] < 1)  & (gns_results['R2'] > -1)]\n",
    "ngns_results = ngns_results[(ngns_results['R2'] < 1)  & (ngns_results['R2'] > -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbfb425-314b-4198-9c81-6ac982fa2539",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.dropna(how = 'any', inplace = True)\n",
    "#GPT has lower error and higher range of p values/r-squared values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941355b-5d2d-41c5-9ba7-2af325db5373",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('bert_results_frame.csv.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4cd8a2-e108-4e21-8994-bec652b92437",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_14_elec_total['sentenceType'].replace({'NG':'GS'}, inplace = True)\n",
    "subject_14_elec_total['sentenceType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f95c07-071a-4691-8200-b8be74eda5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_r2 = results[['GS_R2','GNS_R2','NGNS_R2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4f9014-fbdf-4bb5-a4ab-843840b2c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If looking for summary information/stats run this cell\n",
    "\"\"\"\n",
    "print('number of sentences')\n",
    "len(sentences)\n",
    "print('value counts of sentence types and modalities')\n",
    "print(sentence_solo_total['sentenceType'].value_counts())\n",
    "print(sentence_solo_total['modality'].value_counts())\n",
    "print('neural sentence value counts, one row per modality per electrode <- 161 electrodes')\n",
    "print(elec_final['sentenceType'].value_counts())\n",
    "print('Subject info')\n",
    "print(elec_final['sub_id'].value_counts())\n",
    "print('151 time stamps per electrode per condition')\n",
    "print('modality info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d1ff1a-928e-4562-bea6-6c7c54609061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8967f-5cfc-468b-9e41-437173e500dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out high errors (adjust threshold as needed)\n",
    "mse_threshold = 10000  # Adjust this threshold based on your requirements\n",
    "filtered_results = results[(results['GS_MSE'] < mse_threshold) & (results['GNS_MSE'] < mse_threshold) & (results['NGNS_MSE'] < mse_threshold)]\n",
    "\n",
    "# Plot histograms for R2 values, 20 electrodes per plot\n",
    "log_transform_constant = 1e-6\n",
    "num_electrodes = len(filtered_results)\n",
    "num_plots = (num_electrodes // 20) + (1 if num_electrodes % 20 else 0)\n",
    "conditions = ['GS', 'GNS', 'NGNS']\n",
    "colors = {'GS': 'blue', 'GNS': 'green', 'NGNS': 'red'}\n",
    "\n",
    "for plot_idx in range(num_plots):\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "    start_idx = plot_idx * 20\n",
    "    end_idx = min(start_idx + 20, num_electrodes)\n",
    "    electrodes = filtered_results.index[start_idx:end_idx]\n",
    "    \n",
    "    bar_width = 0.25\n",
    "    x = np.arange(len(electrodes))\n",
    "    \n",
    "    for i, condition in enumerate(conditions):\n",
    "        r2_values = filtered_results.loc[electrodes, f'{condition}_R2']\n",
    "        ax.bar(x + i * bar_width, r2_values + log_transform_constant, bar_width, color=colors[condition], label=condition)\n",
    "    \n",
    "    ax.set_title(f'R Values for Electrodes {start_idx + 1} to {end_idx}')\n",
    "    ax.set_xlabel('Electrode')\n",
    "    ax.set_ylabel('R (log scale)')\n",
    "    ax.set_xticks(x + bar_width)\n",
    "    ax.set_xticklabels(electrodes)\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5f5a0-f0f3-4761-a891-4c7add96cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now only do significant electrodes\n",
    "significant_threshold = 0.05\n",
    "significant_results = filtered_results[\n",
    "    (filtered_results['GS_p_value'] < significant_threshold) |\n",
    "    (filtered_results['GNS_p_value'] < significant_threshold) |\n",
    "    (filtered_results['NGNS_p_value'] < significant_threshold)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d55b8a-9747-486c-90b0-b73a4703dc56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_significance_asterisks(p_value):\n",
    "    if p_value < 0.001:\n",
    "        return '***'\n",
    "    elif p_value < 0.01:\n",
    "        return '**'\n",
    "    elif p_value < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "for plot_idx in range(num_plots):\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "    start_idx = plot_idx * 20\n",
    "    end_idx = min(start_idx + 20, num_electrodes)\n",
    "    electrodes = significant_results.index[start_idx:end_idx]\n",
    "    \n",
    "    bar_width = 0.25\n",
    "    x = np.arange(len(electrodes))\n",
    "    \n",
    "    for i, condition in enumerate(conditions):\n",
    "        r2_values = significant_results.loc[electrodes, f'{condition}_R2']\n",
    "        p_values = significant_results.loc[electrodes, f'{condition}_p_value']\n",
    "        bars = ax.bar(x + i * bar_width, r2_values + log_transform_constant, bar_width, color=colors[condition], label=condition)\n",
    "        \n",
    "        for bar, p_value in zip(bars, p_values):\n",
    "            significance = get_significance_asterisks(p_value)\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), significance, ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    ax.set_title(f'R Values for Electrodes {start_idx + 1} to {end_idx} (Significant)')\n",
    "    ax.set_xlabel('Electrode')\n",
    "    ax.set_ylabel('R (log scale)')\n",
    "    ax.set_xticks(x + bar_width)\n",
    "    ax.set_xticklabels(electrodes)\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    #159/161 electrode significant in GS condition but only 1 star p value. high error with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf59f8-d0b4-4654-a915-9aba39d6fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GPT-2-XL and BERT embedding extraction functions below can use torch to save embedding lists to avoid repeat operations\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80993879-de99-4a6f-b091-6076a7a4c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "246b0c6c-eebe-42e8-a0b8-98d7310a0b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "model = GPT2Model.from_pretrained('gpt2-xl')\n",
    "\n",
    "\n",
    "def get_gpt2_embeddings(sentences, batch_size=32):\n",
    "    embeddings = []\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # Process sentences in batches\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        print('batch', i+1)\n",
    "        batch = sentences[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize the input sentences\n",
    "        inputs = inputs = tokenizer(batch, padding=True, return_tensors='pt')\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Extract the last hidden states\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        \n",
    "        # Average the token embeddings to get sentence embeddings\n",
    "        sentence_embeddings = last_hidden_states.mean(dim=1)\n",
    "        \n",
    "        embeddings.append(sentence_embeddings)\n",
    "        \n",
    "    \n",
    "    # Concatenate all embeddings\n",
    "    embeddings = torch.cat(embeddings, dim=0)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2394b6-0919-410c-be0c-4c4cd80a2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle the pad token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ffd765-354a-4f36-9a75-e9fa06878413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Both BERT and GPT tokenizers require the sentences to be joined\n",
    "\"\"\"\n",
    "def join_words_to_sentences(list_of_word_lists):\n",
    "    return [' '.join(words) for words in list_of_word_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854e204-df0e-47af-aa65-cf0280620803",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_joined = join_words_to_sentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "957add2d-bee7-4288-952c-d8d93f20f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_embeddings = torch.load('./sentence_embeddings.pt')\n",
    "#get_gpt2_embeddings(sentences_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cec3c0-4097-4b5e-b088-104789287c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming embeddings is the tensor you want to save\n",
    "torch.save(gpt_embeddings, 'sentence_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8b5a9-34f3-4ba3-8593-da59cc6db0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "def get_bert_embeddings(sentences, batch_size=32):\n",
    "    embeddings = []\n",
    "    \n",
    "    # Process sentences in batches\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize the input sentences\n",
    "        inputs = tokenizer(batch, padding=True, return_tensors='pt', truncation=True)\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Extract the last hidden states\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        \n",
    "        # Average the token embeddings to get sentence embeddings\n",
    "        sentence_embeddings = last_hidden_states.mean(dim=1)\n",
    "        \n",
    "        embeddings.append(sentence_embeddings)\n",
    "    \n",
    "    # Concatenate all embeddings\n",
    "    embeddings = torch.cat(embeddings, dim=0)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Example usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e38bb5-e58c-4b35-a20c-aacad969e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_bert_embeddings(sentences_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de159635-7958-4e70-8c93-9ea520923867",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeddings, 'sentence__embeddings_bert.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fbd7ed-b078-4192-b853-bf87b40a7cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embed = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14758eee-f99e-4f01-be13-8e8c6672597a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
