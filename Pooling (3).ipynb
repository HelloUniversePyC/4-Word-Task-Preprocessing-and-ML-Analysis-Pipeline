{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83affe-00ed-4759-b397-aeb11337f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wheel\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from mat4py import loadmat\n",
    "import scipy.io\n",
    "import csv\n",
    "import struct\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colormaps\n",
    "#from mne_bids import BIDSPath, read_raw_bids\n",
    "from scipy.signal import butter, filtfilt,welch\n",
    "from scipy.stats import zscore \n",
    "#from mne.time_frequency import tfr_multitaper\n",
    "import seaborn as sb\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk\n",
    "import tkinter as tk\n",
    "#import mne\n",
    "#from mne.viz import plot_alignment, snapshot_brain_montage\n",
    "#import mne_bids\n",
    "#from mne.channels import make_standard_montage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import dask\n",
    "import dask.dataframe as dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e1f0f-618a-4b76-9dbf-a1820d920bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3ec0e3-66fe-41ba-bf2a-f835ebf5ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f900bde-a43b-4450-b686-eb9dee334314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will be populated with all subjects \n",
    "global sub_obj_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a01831-ab70-48d0-acf1-e70f4fa24d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vis_w2ver = arr_find_in_sentence_v2(trigger_frame, 2, \"ver\", 2)\n",
    "\n",
    "def arr_find_in_sentence_v2(trigger_frame, ev_num, w_type, modality) -> list:\n",
    "    \"\"\"Aligns triggers and creates np.array 0/1 mapping of which events in trigger_list fit the event pattern type\"\"\"\n",
    "    # Take number of rows in the trigger list\n",
    "    n_events = len(trigger_frame)\n",
    "    # Create a binary mapping that starts with every value being false\n",
    "    sel = np.zeros(n_events, dtype=bool)\n",
    "    # Looping through all events\n",
    "    for i in range(n_events):\n",
    "        #Take the current row \n",
    "        event = trigger_frame.iloc[i].to_dict()\n",
    "        #pull off the sentence dictionary\n",
    "        sentence = event['sentence']\n",
    "        #grab the event type\n",
    "        event_type = event['Type']\n",
    "        #Go into a switch case like logical statement to determine how to set the mapping\n",
    "        try:\n",
    "            if sentence != {} and ('w1Type' in sentence or 'relatedImage' in sentence):\n",
    "                match = False\n",
    "                if ev_num == 1 and 'w1Type' in sentence:\n",
    "                    match = sentence['w1Type'] == w_type and 'WORD1' in event_type\n",
    "                elif ev_num == 2 and 'w2Type' in sentence:\n",
    "                    match = sentence['w2Type'] == w_type and 'WORD2' in event_type\n",
    "                elif ev_num == 3 and 'w3Type' in sentence:\n",
    "                    match = sentence['w3Type'] == w_type and 'WORD3' in event_type\n",
    "                elif ev_num == 4 and 'w4Type' in sentence:\n",
    "                    match = sentence['w4Type'] == w_type and 'WORD4' in event_type\n",
    "                elif ev_num == 5 and 'sentenceType' in sentence:\n",
    "                    match = sentence['sentenceType'] == w_type and 'WAIT' in event_type\n",
    "                elif ev_num == 6 and 'relatedImage' in sentence:\n",
    "                    match = sentence['relatedImage'] == w_type and 'QUESTION' in event_type\n",
    "                elif ev_num == 7 and 'Type' in sentence:\n",
    "                    match = sentence['Type'] == w_type and 'SW_WORD' in event_type\n",
    "                elif ev_num == 8 and 'SW_HASH' in event_type:\n",
    "                    match = True\n",
    "\n",
    "                if match:\n",
    "                    sel[i] = True\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    #In the case of an ev_num less than 7 take into count audio or visual within the type field\n",
    "    if ev_num < 7:\n",
    "        aud_sel = np.array(['_AUD' in event['Type'] for event in trigger_frame.to_dict('records')])\n",
    "        vis_sel = np.array(['_VIS' in event['Type'] for event in trigger_frame.to_dict('records')])\n",
    "        #In modality audio is a and visual is v\n",
    "        if modality == 1:\n",
    "            sel = sel & aud_sel\n",
    "        else:\n",
    "            sel = sel & vis_sel\n",
    "   \n",
    "    return sel.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f59ce01-abb7-4774-a36a-de89724dd7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global vars for preprocessing\n",
    "tapers = [3, 4]\n",
    "params_Hgamma = {\n",
    "    'fpass': [30, 150],  # Frequency range\n",
    "    'tapers': tapers,\n",
    "    'Fs': 1000, # Sampling frequency\n",
    "    'trialave': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc7bdd2-51c9-46ac-92ea-918c986eecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def notch_filter(data, fs, freq=60.0, quality_factor=30.0):\n",
    "    b_notch, a_notch = butter(2, [freq - 1, freq + 1], btype='bandstop', fs=fs)\n",
    "    return filtfilt(b_notch, a_notch, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e589bc0c-be7f-4ad8-b328-252f292cc113",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gamma_bandpass_filter(data, fs, low_freq=30, high_freq=150):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = low_freq / nyquist\n",
    "    high = high_freq / nyquist\n",
    "    b, a = butter(3, [low, high], btype='band')\n",
    "    return filtfilt(b, a, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b2ad2-23f5-438d-ae76-4a9901b57eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gamma_power(data, fs, low_freq=30, high_freq=150):\n",
    "    freqs, psd = welch(data, fs, nperseg=fs)\n",
    "    gamma_mask = (freqs >= low_freq) & (freqs <= high_freq)\n",
    "    return np.mean(psd[gamma_mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f925fe3-a47d-4b11-b1ed-bebafef52c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe299e-b777-4f77-9dd2-248112d3ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Subject:\n",
    "    \"\"\"Class to Create subject objects with identifying variables and methods for loading and analysis\"\"\"\n",
    "    def __init__(self, subject, subNum, record_direc):\n",
    "        self.subInit = subject\n",
    "        self.subNum = subNum\n",
    "        self.record_direc = record_direc\n",
    "        \n",
    "    def load_behav_mat(self):\n",
    "        \"\"\"Used to load in matlab files for behavioral experiment\"\"\"\n",
    "        #Initialize Paths\n",
    "        self.Gen_Path = \"/Volumes/Expansion/4WT/COLLAB-CODE/Alliyah/Sub-Mat-Converted/\"+self.subInit+\"/\"\n",
    "        Curr_State = self.Gen_Path+self.subInit+\"-CurrState.mat\"\n",
    "        Trig_Sentence = self.Gen_Path+self.subInit+\"-sentence.mat\"\n",
    "        Trigger = self.Gen_Path+self.subInit+\"-trig.mat\"\n",
    "        \n",
    "        #Loading in neccesary raw files\n",
    "        self.curr_raw = scipy.io.loadmat(Curr_State,squeeze_me=True, struct_as_record = False, simplify_cells = True)\n",
    "        self.trig_raw = scipy.io.loadmat(Trigger, squeeze_me=True, struct_as_record = False, simplify_cells = True)\n",
    "        self.sentence_raw = scipy.io.loadmat(Trig_Sentence, squeeze_me=True, struct_as_record = False, simplify_cells = True)\n",
    "        \n",
    "        #Creating seperate data frames of the nested struct fields\n",
    "        self.presentation_matrix_frame = pd.DataFrame(self.curr_raw['curr_state_export']['presentation_matrix'])\n",
    "        self.trigger_frame = pd.DataFrame(self.trig_raw['trigg_list'])\n",
    "        self.file_frame = pd.DataFrame(list(self.curr_raw['curr_state_export']['filenames']))\n",
    "        \n",
    "    def convert_behav_mats(self):\n",
    "        \"\"\"Used to create processed dataframes from raw matlab files\"\"\"\n",
    "        #First handle curr_state\n",
    "        curr_state_slice = self.curr_raw['curr_state_export']\n",
    "        #Create seperate dictionary of all columns that can be resolved to just a constant\n",
    "        self.constants = list(curr_state_slice.keys())\n",
    "        #remove the class type fields\n",
    "        self.constants.remove('trigger_list')\n",
    "        self.constants.remove('presentation_matrix')\n",
    "        self.constants.remove('blockList')\n",
    "        self.constants.remove('filenames')\n",
    "        #Use dictionary comprehension to only keep primitive type data in final dictionary\n",
    "        self.constants_frame = {key: curr_state_slice[key] for key in self.constants}\n",
    "\n",
    "        #Handle trigger_frame\n",
    "        #replacing MATLAB opaque sentences with properly parsed ones\n",
    "        sentence_dict = self.sentence_raw['sentence_work']\n",
    "        self.trigger_frame['sentence'] = sentence_dict\n",
    "\n",
    "    def load_neuro_mat(self):\n",
    "        \"\"\"Load in neurological files\"\"\"\n",
    "        #Load in hdr\n",
    "        global df_saves\n",
    "        hdr_path = self.Gen_Path+self.subInit+\"-hdr.mat\"\n",
    "        self.hdr_raw = curr_raw = scipy.io.loadmat(hdr_path,squeeze_me=True, struct_as_record = False, simplify_cells = True)\n",
    "\n",
    "        #Handle record\n",
    "        record_path = \"/Volumes/Expansion/4WT/4WT-analysis/DATA/mainfiles/\"+self.record_direc+\"/neuralMatfile/FILE1.mat\"\n",
    "        #If nothing catched load\n",
    "        save_id = self.subInit+\"_record\"\n",
    "        \n",
    "        with h5py.File(record_path, 'r', driver = 'sec2') as f: #memory mapping\n",
    "            record = f['record'][:] \n",
    "        self.record = pd.DataFrame(record)\n",
    "        del record \n",
    "        #Otherwise refer to Cache\n",
    "\n",
    "    def convert_neuro_mat(self):\n",
    "        #Handle non-class columns of hdr\n",
    "        \"\"\"Convert neurological mat files to dataframes\"\"\"\n",
    "        prim_keys = ['ver', 'patientID', 'recordID', 'startdate', 'starttime', 'bytes', 'records', 'duration', 'ns', 'label', 'labelNew']\n",
    "            \n",
    "        hdr_class_dict = {key: value for key, value in self.hdr_raw['hdr'].items() if key not in prim_keys and key not in ['labelNew2', 'labelOld']}\n",
    "\n",
    "       \n",
    "       \n",
    "        self.hdr_frame = pd.DataFrame(hdr_class_dict)\n",
    "        self.hdr_prim_dict= {key: value for key, value in self.hdr_raw['hdr'].items() if key in prim_keys}\n",
    "        #placing labels in a seperate list\n",
    "        self.labels = list(self.hdr_raw['hdr']['label'])\n",
    "\n",
    "    def pre_process_gamma(self):\n",
    "        \"\"\"These can be changed if you want to look into other variables like modality (code a or v) /part of speech etc. \n",
    "        See gamma script in 4WT dropbox folder for examples of other valid variable types to examine\n",
    "        \"\"\"\n",
    "        aud_wwS1 = arr_find_in_sentence_v2(self.trigger_frame, 5, \"GS\", 1)\n",
    "        aud_wwS2 = arr_find_in_sentence_v2(self.trigger_frame, 5, \"GNS\", 1)\n",
    "        aud_wwS3 = arr_find_in_sentence_v2(self.trigger_frame, 5, \"NGNS\", 1)\n",
    "\n",
    "        record = self.record.transpose()\n",
    "        nElecs = len(self.labels)\n",
    "        fs = self.hdr_frame.frequency[0]\n",
    "        timeFIXBSL = -400\n",
    "        timeWord = 1100\n",
    "        idxFIXBSL = int(np.ceil(timeFIXBSL * fs / 1000))\n",
    "        idxWord = int(np.ceil(timeWord * fs / 1000))\n",
    "        sizeTime = idxWord - idxFIXBSL\n",
    "\n",
    "        # Ensure correct indexing for triggers\n",
    "        idxFX_S1 = np.where(aud_wwS1)[0] - 5 + 1\n",
    "        idxFX_S2 = np.where(aud_wwS2)[0] - 5 + 1\n",
    "        idxFX_S3 = np.where(aud_wwS3)[0] - 5 + 1\n",
    "\n",
    "        # Initialize arrays for filtered values\n",
    "        filtered_data_S1 = np.zeros((nElecs, len(idxFX_S1)))\n",
    "        filtered_data_S2 = np.zeros((nElecs, len(idxFX_S2)))\n",
    "        filtered_data_S3 = np.zeros((nElecs, len(idxFX_S3)))\n",
    "\n",
    "        for elecNum in range(nElecs):\n",
    "            try:\n",
    "                # Perform bipolar montage\n",
    "                elecSignal = record.iloc[elecNum, :] - record.iloc[elecNum + 1, :] if elecNum < nElecs - 1 else record.iloc[elecNum, :]\n",
    "                \n",
    "                # Apply notch filter and gamma band-pass filter\n",
    "                elecSignal = gamma_bandpass_filter(notch_filter(elecSignal, fs), fs)\n",
    "\n",
    "                if np.any(np.isnan(elecSignal)):\n",
    "                    print(f\"NaN values found in electrode {elecNum + 1}\")\n",
    "                    continue\n",
    "\n",
    "                # Extract gamma power for each condition\n",
    "                gamma_power_S1 = [extract_gamma_power(elecSignal[self.trigger_frame.iloc[idx]['Var1'] + idxFIXBSL:self.trigger_frame.iloc[idx]['Var1'] + idxWord], fs) \n",
    "                                  for idx in idxFX_S1 if self.trigger_frame.iloc[idx]['Var1'] + idxWord < len(elecSignal) and self.trigger_frame.iloc[idx]['Var1'] + idxFIXBSL >= 0]\n",
    "                gamma_power_S2 = [extract_gamma_power(elecSignal[self.trigger_frame.iloc[idx]['Var1'] + idxFIXBSL:self.trigger_frame.iloc[idx]['Var1'] + idxWord], fs) \n",
    "                                  for idx in idxFX_S2 if self.trigger_frame.iloc[idx]['Var1'] + idxWord < len(elecSignal) and self.trigger_frame.iloc[idx]['Var1'] + idxFIXBSL >= 0]\n",
    "                gamma_power_S3 = [extract_gamma_power(elecSignal[self.trigger_frame.iloc[idx]['Var1'] + idxFIXBSL:self.trigger_frame.iloc[idx]['Var1'] + idxWord], fs) \n",
    "                                  for idx in idxFX_S3 if self.trigger_frame.iloc[idx]['Var1'] + idxWord < len(elecSignal) and self.trigger_frame.iloc[idx]['Var1'] + idxFIXBSL >= 0]\n",
    "\n",
    "                # Store gamma power in the arrays\n",
    "                filtered_data_S1[elecNum, :len(gamma_power_S1)] = gamma_power_S1\n",
    "                filtered_data_S2[elecNum, :len(gamma_power_S2)] = gamma_power_S2\n",
    "                filtered_data_S3[elecNum, :len(gamma_power_S3)] = gamma_power_S3\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing electrode {elecNum + 1}: {e}\")\n",
    "\n",
    "        # Create DataFrames with filtered data\n",
    "        filtered_df_S1 = pd.DataFrame(filtered_data_S1, index=self.labels)\n",
    "        filtered_df_S2 = pd.DataFrame(filtered_data_S2, index=self.labels)\n",
    "        filtered_df_S3 = pd.DataFrame(filtered_data_S3, index=self.labels)\n",
    "\n",
    "        return filtered_df_S1, filtered_df_S2, filtered_df_S3\n",
    "     \n",
    "\n",
    "# Usage example:\n",
    "# processor = GammaProcessor(record, trigger_frame, hdr_frame, labels)\n",
    "# zscored_S1, zscored_S2, zscored_S3 = processor.pre_process_gamma()\n",
    "\n",
    "\n",
    "    def create_sentence_frame(self):\n",
    "        \"\"\"Create frame of just the sentence data\"\"\"\n",
    "        empty_dict = {'w1': '','w2': '','w3': '','w4': '','EN_translation': '','imageFile': '','falseImageFile': '','relatedImage': '','sentenceType': '','w1Type': '','w2Type': '','w3Type': '','w4Type': '','w1SoundFile': '','w2SoundFile': '','w3SoundFile': '','w4SoundFile': '','modality': ''\n",
    "}\n",
    "        corr_map = {'W1':'w1','W2':'w2','W3':'w3','W4':'w4','word1type':'w1Type','word2type':'w2Type','word3type':'w3Type','word4type':'w4Type','falseimageFile': 'falseImageFile'}\n",
    "        #Getting rid of Matlab empty maps within the raw data\n",
    "        count = 0\n",
    "        #Un-nesting the dictionaries\n",
    "        for i in range(len(self.trigger_frame['sentence'])):\n",
    "            self.trigger_frame.at[i, 'sentence'] = self.trigger_frame.at[i, 'sentence']['sen_field']\n",
    "        \n",
    "        #Handle empty maps and rows not fitting the expected sentence dictionary format\n",
    "        for i in range(len(self.trigger_frame['sentence'])):\n",
    "            if not isinstance(self.trigger_frame.loc[i, 'sentence'], dict):\n",
    "                self.trigger_frame.at[i, 'sentence'] = empty_dict\n",
    "            if 'word' in self.trigger_frame.loc[i, 'sentence'] or 'type' in self.trigger_frame.loc[i, 'sentence']:\n",
    "                self.trigger_frame.drop(i)\n",
    "                count+=1\n",
    "\n",
    "        \n",
    "        #Create list from column\n",
    "        sen_list = list(self.trigger_frame['sentence'])\n",
    "        #print(sen_list[200]) \n",
    "        #replace incorrect keys \n",
    "        for i,item in enumerate(sen_list):\n",
    "            for key in corr_map:\n",
    "                if key in item:\n",
    "                    sen_list[i][corr_map[key]] = sen_list[i].pop(key)\n",
    "                sen_list[i]['Type'] = self.trigger_frame['Type']\n",
    "                    \n",
    "        sen_frame = pd.DataFrame(sen_list, columns = ['w1', 'w2', 'w3', 'w4', 'imageFile', 'falseImageFile', 'relatedImage', 'sentenceType', 'w1Type', 'w2Type', 'w3Type', 'w4Type', 'modality','Type'])\n",
    "        sen_frame.dropna(inplace = True, how = 'any')\n",
    "        return sen_frame    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643bd7c-d90c-4920-8802-840a34c068ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = [\"s1_ND_EN\",\"s2_TW\",\"s3_BCH_EN\",\"s4_BWH_EN\",\"s5_BWH_EN\",\"s6_TW_leftHanded_male\",\"s7_TW_rightHandedMale\",\"s8_ccf_SANN001\",\"s9_ccf_SANN002\",\"s10_ccf_SANN003\",\"s11_ccf_SANN004\",\"s12_ccf_SANN005\", \"s13_ccf_SANN006\",\"s14_ccf_SANN007\",\"s15_ccf_SANN009\",\"s16_ccf_SANN010\",\"s17_ccf_SANN011\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d1f1d-e872-4637-8b1e-3c0fd29b416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_dict() -> dict:\n",
    "    \"\"\"Loads a dictionary of subject objects to simplify variable access subject_obj_dict[S#] <- access pattern\"\"\"\n",
    "    sub_obj_dict = {}\n",
    "    for i in range(1,18):\n",
    "        #Initialize new subject\n",
    "        curr_sub = f\"S{i}\"\n",
    "        curr_direc = directory[i-1]\n",
    "        sub_obj_dict[curr_sub] = Subject(curr_sub,i,curr_direc)\n",
    "        sub_obj_dict[curr_sub].load_behav_mat()\n",
    "        sub_obj_dict[curr_sub].convert_behav_mats()\n",
    "    return sub_obj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea2fa4-0daf-4141-a4a9-910d2f13e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary used to store subject objects\n",
    "#consider caching this\n",
    "sub_obj_dict = create_sub_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f88fbe-78b3-4aed-b6f9-98e8614a3658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_pool() -> pd.DataFrame:\n",
    "    \"\"\"Creates a pooled and cleaned dataframe of all the behavioral sentence data with identifying subject number per column\"\"\"\n",
    "    dataframes = []\n",
    "    for i,sub in enumerate(sub_obj_dict):\n",
    "        curr_sentence = sub_obj_dict[sub].create_sentence_frame()\n",
    "        curr_sentence['sub_id'] = i+1\n",
    "        print(sub)\n",
    "        print(curr_sentence.shape)\n",
    "        dataframes.append(curr_sentence)\n",
    "        print(\"Dataframe Created and Appended\")\n",
    "        print() \n",
    "    total_sentence = pd.concat(dataframes, ignore_index = True)\n",
    "    return total_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b883f-5a5a-4112-81a9-94133c93b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentence_input = sentence_pool() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d36a75-f227-4492-baaa-a228f1fbda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1773c5b7-9d7e-4695-9c51-5e4c56453a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dab20e-17e6-4b88-ad0f-3371905e054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_input.to_csv('sentence_data.csv.gz', compression = 'gzip') #Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952a5c5-a74c-4af1-b859-72af79b218f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pool neural data\n",
    "def neural_pool(sub_lst):\n",
    "    \"\"\"Loads in, pre-processes, and pools all the SEEG data into a flat dataframe with identifying subject number\"\"\"\n",
    "    gs_lst = []\n",
    "    gns_lst = []\n",
    "    ngns_lst = [] \n",
    "    for sub in sub_lst:\n",
    "        #Load the neural data\n",
    "        print(\"On Subject \", sub)\n",
    "        print(\"Loading and Converting neural data\")\n",
    "        sub_obj_dict[sub].load_neuro_mat()\n",
    "        sub_obj_dict[sub].convert_neuro_mat()\n",
    "        #Pre-Process the neural data\n",
    "        print(\"Processing Gamma\")\n",
    "        GS_record, GNS_record, NGNS_record= sub_obj_dict[sub].pre_process_gamma()\n",
    "        print(\"List appending\")\n",
    "        gs_lst.append(GS_record)\n",
    "        gns_lst.append(GNS_record)\n",
    "        ngns_lst.append(NGNS_record)\n",
    "    #Combine all the frames together\n",
    "    print(\"Concating\")\n",
    "    total_gs = pd.concat(gs_lst, ignore_index = True)\n",
    "    total_gns = pd.concat(gns_lst, ignore_index = True)\n",
    "    total_ngns = pd.concat(ngns_lst, ignore_index = True)\n",
    "    return total_gs,total_gns,total_ngns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757fa33a-4cfb-4304-92bb-3d7aaa69d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_lst = list(sub_obj_dict.keys())\n",
    "iter_lst.pop(2)\n",
    "iter_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f43b5d-f56b-4748-a685-c24bbe6c1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change start arguement to do one at a time\n",
    "for i,sub in enumerate(iter_lst, start = 12):\n",
    "    gs,gns,ngns = neural_pool([iter_lst[i]])\n",
    "    file_1= \"GS_\"+sub+\".csv.gz\"\n",
    "    file_2 = \"GNS_\"+sub+\".csv.gz\"\n",
    "    file_3 = \"NGNS_\"+sub+\".csv.gz\"\n",
    "    print(\"Generating CSV zipped files\")\n",
    "    gs.to_csv(file_1, compression = 'gzip')\n",
    "    gns.to_csv(file_2, compression = 'gzip')\n",
    "    ngns.to_csv(file_3, compression = 'gzip')\n",
    "    print(\"Garbage Collecting\")\n",
    "    del gs\n",
    "    del gns\n",
    "    del ngns\n",
    "    print(\"Done!\") \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45213b4c-22b7-42e3-bd6e-a929f128d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'rb') as csvfile:\n",
    "    df = pd.read_csv(csvfile,compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6840c-297e-4208-b48d-4b6b75b5b0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
